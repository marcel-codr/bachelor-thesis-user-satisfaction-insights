@article{DeloneMcLean2003ISSuccessTenYearUpdate,
    author = {Delone, McLean},
    title = {The DeLone and McLean Model of Information Systems Success: A Ten-Year Update},
    journal = {Journal of Management Information Systems},
    year = {2003}
}

@inproceedings{Sahin2024LLM_proceedings,
  author    = {{\c{S}}ahin, G{\"u}rkan and Varol, Karya and Pak, Burcu Kuleli},
  title     = {{LLM and RAG-Based Question Answering Assistant for Enterprise Knowledge Management}},
  booktitle = {2024 9th International Conference on Computer Science and Engineering (UBMK)},
  year      = {2024},
  publisher = {IEEE}
}

@misc{Brandt2023,
  title        = {Wie lange brauchen Online-Dienste, um eine Million Menschen zu erreichen},
  author       = {Brandt, Mathias},
  year         = 2023,
  note         = {\url{[https://de.statista.com/infografik/29195/zeitraum-den-online-dienste-gebraucht-haben-um-eine-million-nutzer-zu-erreichen/](https://de.statista.com/infografik/29195/zeitraum-den-online-dienste-gebraucht-haben-um-eine-million-nutzer-zu-erreichen/)} [Zugriff am: 2025-07-31]}
}

@misc{Huber2025,
  title        = {ChatGPT Nutzerzahlen (Stand Juni 2025)},
  author       = {Huber, Sandro},
  year         = 2025,
  note         = {\url{[https://www.sh-digital.ch/blog/chatgpt-nutzerzahlen](https://www.sh-digital.ch/blog/chatgpt-nutzerzahlen)} [Zugriff am: 2025-07-31]}
}

@misc{McKinsey2023,
  title        = {GenAI's implications for Germany's labor market},
  author       = {McKinsey \& Company},
  year         = 2023,
  note         = {\url{[https://www.mckinsey.com/de/~/media/mckinsey/locations/europe\%20and\%20middle\%20east/deutschland/news/presse/2023/2023-11-24\%20genai\%20implikationen\%20deutschlands\%20arbeitsmarkt/en_mckinsey_genai_implications_germany_labor_market.pdf](https://www.mckinsey.com/de/~/media/mckinsey/locations/europe\%20and\%20middle\%20east/deutschland/news/presse/2023/2023-11-24\%20genai\%20implikationen\%20deutschlands\%20arbeitsmarkt/en_mckinsey_genai_implications_germany_labor_market.pdf)} [Zugriff am: 2025-07-31]}
}

@misc{GoogleCloudRAG,
  title        = {What is Retrieval-Augmented Generation (RAG)?},
  author       = {{Google Cloud}},
  year         = {2025},
  howpublished = {\url{https://cloud.google.com/use-cases/retrieval-augmented-generation?hl=en}},
  note         = {Accessed: 2025-07-31}
}

@article{Bruckhaus2024RAG,
  author  = {Bruckhaus, Tilmann},
  title   = {RAG Does Not Work for Enterprises},
  year    = {2024},
  journal = {arXiv preprint arXiv:2406.04369}
}

@inproceedings{Barnett_Kurniawan_Thudumu_Brannelly_Abdelrazek_2024,
    title={Seven failure points when engineering a retrieval augmented generation system},
    DOI={10.1145/3644815.3644945},
    journal={Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
    author={Barnett, Scott and Kurniawan, Stefanus and Thudumu, Srikanth and Brannelly, Zach and Abdelrazek, Mohamed},
    year={2024},
    month={Apr}
}

@inproceedigs{Es_James_Espinosa_Anke_Schockaert_2024,
    title={Ragas: Automated Evaluation of retrieval augmented generation},
    DOI={10.18653/v1/2024.eacl-demo.16},
    journal={Proceedings of the 18th Conference of the European Chapter of the Association for Computational Linguistics: System Demonstrations},
    author={Es, Shahul and James, Jithin and Espinosa Anke, Luis and Schockaert, Steven},
}

@inproceedings{Saad_Falcon_Khattab_Potts_Zaharia_2024,
    title={Ares: An automated evaluation framework for retrieval-augmented generation systems},
    DOI={10.18653/v1/2024.naacl-long.20},
    journal={Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)},
    author={Saad-Falcon, Jon and Khattab, Omar and Potts, Christopher and Zaharia, Matei},
    year={2024}
} 

@article{Davis1989,
   author = {Fred D. Davis},
   doi = {10.2307/249008},
   issn = {02767783},
   issue = {3},
   journal = {MIS Quarterly: Management Information Systems},
   keywords = {End user computing,User acceptance,User measurement},
   pages = {319-339},
   publisher = {Management Information Systems Research Center},
   title = {Perceived usefulness, perceived ease of use, and user acceptance of information technology},
   volume = {13},
   year = {1989}
}

@article{Jennex2006,
   author = {Murray E. Jennex and Lorne Olfman},
   doi = {10.4018/jkm.2006070104},
   issn = {15480658},
   issue = {3},
   journal = {International Journal of Knowledge Management (IJKM)},
   keywords = {knowledge management,knowledge management success,knowledge management systems},
   pages = {51-68},
   title = {A Model of Knowledge Management Success},
   volume = {2},
   year = {2006}
}

@book{Davenport,
    author = {Davenport, Thomas and Prusak, Laurence},
    year = {1998},
    month = {01},
    title = {Working Knowledge: How Organizations Manage What They Know},
    volume = {1},
    journal = {Ubiquity},
    doi = {10.1145/348772.348775}
}

@article{Jennex2006WhatIsKM,
    author = {Jennex, Murray},
    year = {2006},
    month = {01},
    pages = {i-iv},
    title = {What is Knowledge Management?},
    volume = {1},
    isbn = {9781599042633},
    journal = {International Journal of Knowledge Management},
    doi = {10.4018/978-1-59904-261-9.ch001}
}

@misc{MinskyBritannica,
  author = {Dennis, Michael Aaron},
  title = {Marvin Minsky},
  howpublished = {Encyclopedia Britannica. \url{https://www.britannica.com/biography/Marvin-Minsky}},
  year = {2025},
  month = {March},
  day = {5},
  note = {Last updated March 5, 2025; Accessed August 1, 2025}
}

@techReport{Lund2023,
   author = {Brady D Lund and Ting Wang and Nishith Reddy Mannuru and Bing Nie and Somipam Shimray and Ziang Wang},
   title = {ChatGPT and a New Academic Reality: AI-Written Research Papers and the Ethics of the Large Language Models in Scholarly Publishing},
   url = {https://ssrn.com/abstract=4389887},
    year = 2023,
}

@article{Lewis2021,
   abstract = {Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) -- models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, the other can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state-of-the-art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.},
   author = {Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela},
   month = {4},
   title = {Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
   url = {http://arxiv.org/abs/2005.11401},
   year = {2021}
}

@misc{AWS_RAG,
    author = {AWS},
    url = {https://aws.amazon.com/de/what-is/retrieval-augmented-generation/}, journal = {Was ist rag? – retrieval augmented generation ERKLÄRT – AWS}
}

@misc{NStarX_Inc._2025,
    title={The $2.5 million question: Why Data Quality Makes or breaks your enterprise rag system},
    url={https://nstarxinc.com/blog/the-2-5-million-question-why-data-quality-makes-or-breaks-your-enterprise-rag-system/},
    journal={NStarX Inc.},
    author={NStarX Inc.},
    year={2025},
    month={Jul}
}

@techReport{Tilmann,
   abstract = {Retrieval-Augmented Generation (RAG) improves the accuracy and relevance of large language model outputs by incorporating knowledge retrieval. However, implementing RAG in enterprises poses challenges around data security, accuracy, scalability, and integration. This paper explores the unique requirements for enterprise RAG, surveys current approaches and limitations, and discusses potential advances in semantic search, hybrid queries, and optimized retrieval. It proposes an evaluation framework to validate enterprise RAG solutions, including quantitative testing, qualitative analysis, ablation studies, and industry case studies. This framework aims to help demonstrate the ability of purpose-built RAG architectures to deliver accuracy and relevance improvements with enterprise-grade security, compliance and integration. The paper concludes with implications for enterprise deployments, limitations, and future research directions. Close collaboration between researchers and industry partners may accelerate progress in developing and deploying retrieval-augmented generation technology.},
   author = {Tilmann Bruckhaus},
   keywords = {Accuracy and relevance,Compliance-regulated industries,Enterprise AI,Enterprise integration,Enterprise knowledge bases,Evaluation frameworks,Financial services applications,Generative AI,Healthcare applications,Hybrid query strategies,Information retrieval,Language models,Legal domain applications,Regulatory compliance,Retrieval-Augmented Generation (RAG),Semantic search},
   title = {RAG Does Not Work for Enterprises}
}


@misc{GoogleGenAIEvaluation,
    url={https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-overview},
    journal={Google},
    publisher={Google}
} 

@misc{GoogleAnalytics,
    url={https://developers.google.com/analytics/devguides/collection/ga4},
    journal={Google analytics for developers  |  google for developers},
    publisher={Google}
} 

@article{Peffers2007,
   abstract = {The paper motivates, presents, demonstrates in use, and evaluates a methodology for conducting design science (DS) research in information systems (IS). DS is of importance in a discipline oriented to the creation of successful artifacts. Several researchers have pioneered DS research in IS, yet over the past 15 years, little DS research has been done within the discipline. The lack of a methodology to serve as a commonly accepted framework for DS research and of a template for its presentation may have contributed to its slow adoption. The design science research methodology (DSRM) presented here incorporates principles, practices, and procedures required to carry out such research and meets three objectives: it is consistent with prior literature, it provides a nominal process model for doing DS research, and it provides a mental model for presenting and evaluating DS research in IS. The DS process includes six steps: problem identification and motivation, definition of the objectives for a solution, design and development, demonstration, evaluation, and communication. We demonstrate and evaluate the methodology by presenting four case studies in terms of the DSRM, including cases that present the design of a database to support health assessment methods, a software reuse measure, an Internet video telephony application, and an IS planning method. The designed methodology effectively satisfies the three objectives and has the potential to help aid the acceptance of DS research in the IS discipline. © 2008 M.E. Sharpe, Inc.},
   author = {Ken Peffers and Tuure Tuunanen and Marcus A. Rothenberger and Samir Chatterjee},
   doi = {10.2753/MIS0742-1222240302},
   issn = {07421222},
   issue = {3},
   journal = {Journal of Management Information Systems},
   keywords = {Case study,Design science,Design science research,Design theory,Mental model,Methodology,Process model},
   month = {12},
   pages = {45-77},
   title = {A design science research methodology for information systems research},
   volume = {24},
   year = {2007}
}

@misc{GoogleCloudDocumentation,
    url={https://cloud.google.com/docs},
    journal={Google Cloud Documentation},
    publisher={Google}
}

@misc{GoogleVertexAISearch,
    url={https://cloud.google.com/generative-ai-app-builder/docs/introduction#es-and-personalize},
    journal={Google},
    publisher={Google}
}

@misc{GoogleReranker,
    url={https://cloud.google.com/generative-ai-app-builder/docs/ranking#rank_or_rerank_a_set_of_records_according_to_a_query}, journal={Google},
    publisher={Google}
}

@misc{LangChain,
    url={https://www.langchain.com/},
    journal={LangChain}
}

@misc{GoogleGemini,
    url={https://ai.google.dev/gemini-api/docs/models},
    journal={Google},
    publisher={Google}
}

@article{Chan2024,
   abstract = {Large Language Models (LLMs) exhibit remarkable capabilities but are prone to generating inaccurate or hallucinatory responses. This limitation stems from their reliance on vast pretraining datasets, making them susceptible to errors in unseen scenarios. To tackle these challenges, Retrieval-Augmented Generation (RAG) addresses this by incorporating external, relevant documents into the response generation process, thus leveraging non-parametric knowledge alongside LLMs' in-context learning abilities. However, existing RAG implementations primarily focus on initial input for context retrieval, overlooking the nuances of ambiguous or complex queries that necessitate further clarification or decomposition for accurate responses. To this end, we propose learning to Refine Query for Retrieval Augmented Generation (RQ-RAG) in this paper, endeavoring to enhance the model by equipping it with capabilities for explicit rewriting, decomposition, and disambiguation. Our experimental results indicate that our method, when applied to a 7B Llama2 model, surpasses the previous state-of-the-art (SOTA) by an average of 1.9\% across three single-hop QA datasets, and also demonstrates enhanced performance in handling complex, multi-hop QA datasets. Our code is available at https://github.com/chanchimin/RQ-RAG.},
   author = {Chi-Min Chan and Chunpu Xu and Ruibin Yuan and Hongyin Luo and Wei Xue and Yike Guo and Jie Fu},
   month = {3},
   title = {RQ-RAG: Learning to Refine Queries for Retrieval Augmented Generation},
   url = {http://arxiv.org/abs/2404.00610},
   year = {2024}
}

@article{Setty2024,
   abstract = {The effectiveness of Large Language Models (LLMs) in generating accurate responses relies heavily on the quality of input provided, particularly when employing Retrieval Augmented Generation (RAG) techniques. RAG enhances LLMs by sourcing the most relevant text chunk(s) to base queries upon. Despite the significant advancements in LLMs' response quality in recent years, users may still encounter inaccuracies or irrelevant answers; these issues often stem from suboptimal text chunk retrieval by RAG rather than the inherent capabilities of LLMs. To augment the efficacy of LLMs, it is crucial to refine the RAG process. This paper explores the existing constraints of RAG pipelines and introduces methodologies for enhancing text retrieval. It delves into strategies such as sophisticated chunking techniques, query expansion, the incorporation of metadata annotations, the application of re-ranking algorithms, and the fine-tuning of embedding algorithms. Implementing these approaches can substantially improve the retrieval quality, thereby elevating the overall performance and reliability of LLMs in processing and responding to queries.},
   author = {Spurthi Setty and Harsh Thakkar and Alyssa Lee and Eden Chung and Natan Vidra},
   month = {8},
   title = {Improving Retrieval for RAG based Question Answering Models on Financial Documents},
   url = {http://arxiv.org/abs/2404.07221},
   year = {2024}
}

@misc{GoogleBigQuery,
    url={https://cloud.google.com/bigquery/docs},
    journal={Google},
    publisher={Google}
} 

@misc{GoogleCloudRunService,
    url={https://cloud.google.com/run/docs/overview/what-is-cloud-run#cloud_run_services},
    journal={Google},
    publisher={Google}
}

@misc{DSGVO_2024,
    url={https://dsgvo-gesetz.de/},
    journal={Datenschutz-Grundverordnung (DSGVO)},
    year={2024},
    month={Nov}
}

@misc{GoogleEmbedding001,
    url={https://ai.google.dev/gemini-api/docs/embeddings},
    journal={Google},
    publisher={Google}
}

@article{Baligodugula2025,
    author = {Vishnu Vardhan Baligodugula and Fathi Amsaad},
    month = {7},
    title = {Unsupervised Learning: Comparative Analysis of Clustering Techniques on High-Dimensional Data},
    url = {http://arxiv.org/abs/2503.23215},
    year = {2025},
    journal = {}
}

@misc{GoogleGeminiPricing,
    url={https://ai.google.dev/gemini-api/docs/pricing},
    journal={Google},
    publisher={Google}
}

@article{McInnes2020,
   abstract = {UMAP (Uniform Manifold Approximation and Projection) is a novel manifold learning technique for dimension reduction. UMAP is constructed from a theoretical framework based in Riemannian geometry and algebraic topology. The result is a practical scalable algorithm that applies to real world data. The UMAP algorithm is competitive with t-SNE for visualization quality, and arguably preserves more of the global structure with superior run time performance. Furthermore, UMAP has no computational restrictions on embedding dimension, making it viable as a general purpose dimension reduction technique for machine learning.},
   author = {Leland McInnes and John Healy and James Melville},
   month = {9},
   title = {UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction},
   url = {http://arxiv.org/abs/1802.03426},
   year = {2020}
}
